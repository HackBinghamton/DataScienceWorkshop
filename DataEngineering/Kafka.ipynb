{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Kafka?\n",
    "\n",
    "Kafka is a **big data streaming service** that allows multiple sources to upload and download data, such as log files or bug reports. Kafka organizes data and ensures that it is kept in order, and that all data goes where it needs to. Kafka was originally created by LinkedIn, but is now maintained by Apache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messages\n",
    "\n",
    "Kafka transmits data in the form of **messages**, which are small files containing any type of data. Messages are created and transmitted in real-time, and some examples of messages include:\n",
    "- program crash logs\n",
    "- customer support chat records\n",
    "- forms received through a webpage\n",
    "\n",
    "These messages are given to Kafka via API calls. Once a message is given to Kafka, the data is queued and stored in servers until users access the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producers and Consumers\n",
    "\n",
    "Programs or users that create and send data are called **producers**, and programs or users that read data are called **consumers**. There are separate APIs for [producers](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html) and [consumers](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html), and you can find examples of how to use them [here](https://kafka-python.readthedocs.io/en/master/usage.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Topics\n",
    "\n",
    "Producers and consumers subscribe to Kafka topics, which are the structure Kafka uses for **data organization**. A topic is a group of related data that is separated into its own sub-stream. Organizations can pick and choose who has access to which topics, which allows companies to keep data secure by limiting the number of people who have access to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Our First Kafka Program\n",
    "## Setup\n",
    "### Install Zookeeper and Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://apache-mirror.8birdsvideo.com/zookeeper/zookeeper-3.5.5/apache-zookeeper-3.5.5-bin.tar.gz\n",
    "!tar -xzf apache-zookeeper-3.5.5-bin.tar.gz\n",
    "!wget http://www-us.apache.org/dist/kafka/2.3.0/kafka_2.12-2.3.0.tgz\n",
    "!tar -xzf kafka_2.12-2.3.0.tgz\n",
    "!rm *.gz *.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Zookeeper and Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/zookeeper-server-start.sh -daemon kafka_2.12-2.3.0/config/zookeeper.properties\n",
    "!kafka_2.12-2.3.0/bin/kafka-server-start.sh -daemon kafka_2.12-2.3.0/config/server.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Kafka Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic MyHackBUTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Topic Was Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Kafka Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                         value_serializer=lambda x: \n",
    "                         json.dumps(x).encode('utf-8'))\n",
    "\n",
    "for e in range(10):\n",
    "    data = {'number' : e}\n",
    "    producer.send('MyHackBUTopic', value=data)\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'MyHackBUTopic',\n",
    "     bootstrap_servers=['localhost:9092'],\n",
    "     auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True,\n",
    "     group_id='my-group',\n",
    "     value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "\n",
    "for message in consumer:\n",
    "    message = message.value\n",
    "    print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
